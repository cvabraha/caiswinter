{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "data pre processing"
      ],
      "metadata": {
        "id": "0a81Iy0qtnxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# download dataset\n",
        "path = kagglehub.dataset_download(\"rmisra/news-headlines-dataset-for-sarcasm-detection\")\n",
        "\n",
        "print(\"Dataset downloaded to:\", path)\n",
        "print(\"Files in this folder:\", os.listdir(path))\n",
        "\n",
        "# Build file path\n",
        "json_file_path = os.path.join(path, 'Sarcasm_Headlines_Dataset.json')\n",
        "\n",
        "data = []\n",
        "with open(json_file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        data.append(json.loads(line))\n",
        "\n",
        "# Dataframe\n",
        "df = pd.DataFrame(data)\n",
        "df = df[['headline', 'is_sarcastic']]\n",
        "print(f\"Successfully loaded {len(df)} rows.\")\n",
        "\n",
        "def clean_text(t):\n",
        "    t = t.lower()\n",
        "    t = re.sub(r\"http\\S+\", \"url\", t)\n",
        "    t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n",
        "    return t\n",
        "\n",
        "df['clean_text'] = df['headline'].apply(clean_text)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class SarcasmDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['clean_text'].values,\n",
        "    df['is_sarcastic'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Dataloaders\n",
        "train_ds = SarcasmDataset(train_texts, train_labels, tokenizer)\n",
        "val_ds = SarcasmDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=16)"
      ],
      "metadata": {
        "id": "E3RWxADOk35T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize BERT & pass output to an LSTM and then classifier"
      ],
      "metadata": {
        "id": "AtlvHymJt-8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BertLSTMClassifier(nn.Module):\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        super(BertLSTMClassifier, self).__init__()\n",
        "\n",
        "        # BERT\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(input_size=768, hidden_size=128, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Binary classifier\n",
        "        self.classifier = nn.Linear(128 * 2, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        sequence_output = bert_output.last_hidden_state\n",
        "\n",
        "        # BERT --> LSTM\n",
        "        lstm_output, (hidden, cell) = self.lstm(sequence_output)\n",
        "\n",
        "        hidden_final = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(hidden_final)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "8ugNRqdUuG5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "7GDBsuETudCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model and GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertLSTMClassifier(freeze_bert=False) # Set True if training is too slow\n",
        "model = model.to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "    # --- TRAINING ---\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(input_ids, mask)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Average Training Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "    # --- TRAINING EVALUATION ---\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, mask)\n",
        "\n",
        "            # Get predictions (argmax)\n",
        "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            labels = labels.cpu().numpy()\n",
        "\n",
        "            val_preds.extend(preds)\n",
        "            val_true.extend(labels)\n",
        "\n",
        "    # Calculate accuracy Metrics\n",
        "    acc = accuracy_score(val_true, val_preds)\n",
        "    f1 = f1_score(val_true, val_preds)\n",
        "\n",
        "    print(f\"Validation Accuracy: {acc}\")\n",
        "    print(f\"Validation F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "nqmeLxSVufsS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}